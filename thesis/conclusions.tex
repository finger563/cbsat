\chapter{Conclusions and Future Work}
\label{ch:conclusions}

We have described in this thesis the aspects of Cyber-Physical
Systems(CPS) analysis, design, development, and integration we are
addressing.  We have provided descriptions of the relevant related
work in this area, covering both the design-time modeling, analysis,
and performance prediction for networked, distributed, CPS
applications and the run-time monitoring and management of application
and CPS network resources.

Subsequently, the completed research towards precise network
performance prediction, \shorttool/, was presented. 

First, the formalization for the modeling and analysis semantics and
techniques were defined, building off of the $(\wedge,+)-calculus$
used by Network Calculus.  Models of systems and applications were
presented and convolution ($\otimes$) of application profiles with
system profiles was defined.  Using $(\wedge,+)-calclulus$, the
computation of delay and backlog bounds were defined.

Given the definition of the fundamental operations of \shorttool/,
analysis of periodic systems was presented.  We described how periodic
data rate profiles can be time-integrated to produce repeating data
profiles as functions of time.  We proved that the minimum amount of
time for which the system and its applications must be analyzed to
determine if there is unbounded buffer growth is two hyperperiods.

Using experimental system data, we determined the benefit of
\shorttool/ versus similar techniques such as Network Calculus.  We
showed how our techniques provide more accurate predictions with
respect to the actual system but are still conservative predictions.  

We then showed how a model of MAC protocols, such as TDMA, could be
incorporated into the system and application models.  Using these
modles, we analytically derived equations for the effects of such
protocols on the predicted delay and backlog bounds.

The mathematical operations of \shorttool/ were extended to support
compositional system analysis by defining the concepts of profile
addition and subtraction.  For this compositional analysis, the
concept of profile priority was introduced to determine service
precedence by the transmitting node between two profiles.

Since latency is such a critical aspect of networking systems, we
introduced semantics for modeling the delay of network links as a
linear, continuous function of time.  Convolution of a profile with a
delay profile was introduced and its effects on the profile's
periodicity were analyzed.

To support more complex systems which include nodes that can act as
routers and forwarders for traffic from other nodes, we presented an
algorithm that uses the concepts we developed for delay analysis and
compositional analysis to iteratively analyze a system which contains
statically routed traffic.  Experimental validation of this
integrated, system-level analysis was provided to demonstrate the
accuracy and precision of the analysis techniques.  

To support experimental validation and run-time testing, we developed
code generators that generate traffic producer/consumer and
measurement code into the component models we defined.  Using these
producers and consumers, which operate based on the same profiles used
for design-time analysis, we ran experiments which corroborated our
analysis results.

Finally, we extended our traffic producer/consumer code to enable
management of the network traffic by the communications middleware.
Detection code was developed for the receivers to detect when and
which senders were overflowing the receiver's buffer and use an
out-of-band communications channel to inform the sender's middleware
to limit the sender's data production.  

\subsection{Future Work}
\label{subsec:future_work}
In this work we have described the beginning of precise, comprehensive
network system performance analysis and prediction.  However, we could
not possibly cover the modeling and analysis of all possible system
configurations, communication protocols, or interaction paradigms.
Furthermore, we have examined the affect certain system configuration
parameters or modeling choices have on our analysis techniques and
results, but such examination is not exhaustive.

Extending this work would focus on these areas in the following ways:

\begin{itemize}
  \item Modeling and analysis support for more (commonly used)
    transmission protocols, such as TCP or SCTP.
  \item Developing models of other MAC protocols such as CSMA
  \item Deriving models of packet loss or transmission error and
    analyzing their effects on the prediction results
  \item Analyzing the effects of uncertainty in the modeling of
    applications and systems
  \item Research into methods for including models of data-dependent
    network traffic and analyzing such applications
  \item Analyzing the affects of timing and time synchronization
    inaccuracies on the prediction results
  \item Investigating run-time implementation alternatives and data
    analysis techniques
\end{itemize}

To support modeling and analysis of protocols such as TCP, which are
reactive to return-path information, return-path modeling semantics
and analysis techniques would be needed.  Return-path modeling can be
challenging because in the non-trivial case, return-path information
is used to make the application or system protocol reactive to the
current state of the system.  This is the case for instance in TCP
where the timing of the return packets or the lack or return packets
alters the outgoing data flow.  Similarly, lower-level protocol
implementation details like connection management and handshaking can
be affected by variable network capacity, therefore they can
indirectly affect application performance.

This type of return-path modeling and feedback system needed for
modeling such protocols would also benefit the analysis of
data-dependent application profiles, since they similarly are
dependent on some external input which at least partially governs the
characteristics of the traffic they produce.

Similarly, forwarding protocols in the lower layers, such as the store
and forward mechanisms used by certain routers, are also reactive to
data driven events, such as packet loss or packet corruption.  The
modeling and analysis extensions described above would pave the way
for the analysis of the effects on application performance caused by
these lower level protocol mechanisms.

As an extension to the application and system level models, which
currently are precisely defined and assumed to be exactly known,
research into uncertainty analysis of these profiles would allow
performance prediction for systems that do not meet these assumptions
about full knowledge.  If instead of exact knowledge about the system
and application profiles, the application developers and system
integrators have uncertainties associated with their models, then
analysis of the uncertainty and its effect on the predictions would
expand the scope of systems to which the techniques could be applied.

In a similar way to the modeling uncertainty analysis, timing
uncertainty analysis could be performed to determine the affects of
incomplete time synchronization between the nodes of the system.  Such
analysis would allow for the relaxation of the system-wide
time-synchronization constraint.  If that constraint is relaxed such
that the nodes are known be re-synchronized periodically with some
predictable drift, then such behavior can be directly analyzed
similarly to the TDMA analysis.  From this information, maximum
deviations on the required buffer and delay can be calculated,
similarly to the deviations calculated for TDMA systems.

Finally, the analysis of application traffic profiles provides a
possible avenue for precise categorization of application behavior.
Given an application which is supposed to produce traffic with a
certain profile, middleware-based measurements of the actual traffic
profile produced by the application can allow the middleware or other
management entity to classify the behavior of the application.
Analyzing this behavior and comparing it with the behavior of other
applications in the system would allow for better detection of faults,
malicious behavior, or other anomalies.  
