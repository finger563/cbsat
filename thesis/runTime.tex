\chapter{Run-Time Network Performance Monitoring and Management for Distributed CPS Applications}
\label{ch:runTime}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Middleware-Integrated Measurement, Detection, and Enforcement}
\label{sec:middleware}

\begin{figure}[ht!]
  \centering
  \includegraphics[width=0.85\textwidth]{../doc/src/images/results/ros_component.png}
  \caption{Schematic representation of a software component.}
  \label{fig:component}
\end{figure}

Our run-time research and development of measurement, detection, and
enforcement code for networked applications is built on the foundation
of component-based software engineering (CBSE).  The goal of CBSE is
to provide a reusable framework for the development of application
building-blocks, called \emph{components} so that developers can develop
and \emph{analyze} applications in a more robust and scalable manner.  In
CBSE, a \emph{component}, shown schematically in
Figure~\ref{fig:component}, is the smallest deployable part of an
application and is defined as:

\begin{equation}
  C = \{\{T\},\{P\},H\}
\end{equation}

Where

\begin{itemize}
\item $\{T\}$ is the \emph{set} of all \emph{timers} within the component.  A
  timer provides a periodic event trigger to the component which
  triggers the callback associated with $T$, where a callback is a
  function defined and implemented by the developer.  
\item $\{P\}$ is the \emph{set} of all \emph{input/output ports} within the
  component.  An i/o port provides a mechanism for message passing and
  event triggering between components, and may take the form of
  asynchronous \emph{publish/subscribe} or synchronous \emph{client/server}
  interaction patterns.  Similarly to timers, each incoming event
  triggers the callback associated with $P$.
\item $H$ is the single thread which executes all event events for
  the component, in FIFO order, without preemption.  
\end{itemize}

From this component definition, we can define an application as:

\begin{equation}
  A = \{\{C\},\{M\}\}
\end{equation}

Where

\begin{itemize}
\item $\{C\}$ is the \emph{set} of components in the application
\item $\{M\}$ is the \emph{set} of \emph{mappings} between ports of
  the components in $\{C\}$, for instance connecting a subscriber of
  $C_x$ to a publisher of $C_y$, $M_{x,y} : C_x\{P_S\}\mapsto
  C_y\{P_P\}$.
\end{itemize}

And finally, an application's components are grouped into processes
and distributed onto the nodes of a system through a deployment
defined as:

\begin{equation}
  D = \{\{N\},\{U\},\{M\}\}
\end{equation}

Where

\begin{itemize}
\item $\{N\}$ is the \emph{set} of hardware \emph{nodes} in the system
\item $\{U\}$ is the \emph{set} of \emph{processes} defining the deployment,
  where a process is a collection of components
  $U=\{C\}\subseteq A\{\{C\}\}$.
\item $\{M\}$ is the \emph{set} of \emph{mappings} between processes and nodes
  in the system, e.g. $M_{U_1,N_1} : U_1\mapsto N_1$.
\end{itemize}

Note here that though the components may be single threaded
internally, the application containing these components may run them
in parallel, e.g. by grouping them into a process or distributing them
among the hardware nodes of the system.  An example application and
deployment onto a system of nodes is shown in Figure~\ref{fig:cbse}.
Note that multiple applications (shades of blue in this figure) may be
deployed simultaneously onto the same system and may even interact
with each other.

\begin{figure}[ht!]
  \centering
  \includegraphics[width=0.85\textwidth]{../doc/src/images/results/cbse.png}
  \caption{Two example distributed CBSE applications deployed on a system with
    4 nodes.}
  \label{fig:cbse}
\end{figure}
   
We have implemented these features based on our design-time results:

\begin{itemize}
\item Traffic production according to sender profile generated into
  sender code
\item Traffic consumption according to receiver profile generated into
  receiver code
\item Measurement of output traffic on sender side and input traffic on
  server side generated into code
\item Detection of anomalous sending on sender side
\item Mitigation of anoumalous sending on sender side
\item Detection of anomalous sending on receiver side
\item Push back to sender middleware through out-of-band channel for
  anomaly detection on server side
\end{itemize}

Each of these functions uses the same profiles which enable
design-time system and application analysis.  This integration not
only helps with running experiments and data collection but also helps
to ensure model to system consistency.
  
\begin{figure}[ht!]
  \centering
  \includegraphics[width=0.85\textwidth]{../doc/src/images/results/app_layers.png}
  \caption{The structure of component-based applications and how their network
   traffic traverses the middleware and the OS stack.}
  \label{fig:sender}
\end{figure}

We have implemented profile-based traffic production/consumption and
traffic measurement into our code generators that we use with our
model-driven design software.  We developed this toolsuite to create
distributed component-based software which uses the Robot Operating
System (ROS)\cite{ros} as the communications middleware.  ROS provides
the capability for managing message passing, event triggering, and
timer triggering that we need for our software components.  For
publish/subscribe interactions between components, into the
publisher's generated code we add generic traffic producer code which
publishes traffic according to the sender profile.  Additionally,
these publish operations are configured to use a small wrapper
function which can measure the publish rate and can decide to throw a
\emph{profile exceeded} exception if the application attempts to send
too much data or if the receiver has pushed back to the sender
informing it to stop.  The sender-side middleware layer is shown in
Figure~\ref{fig:sender}.

This push back from the receiver occurs through the use of an
out-of-band (OOB) channel using UDP multicast, which receivers use to
inform specific senders that they are sending too much data to the
receivers (and possibly overflowing the receiver buffers).  This OOB
channel provides a mechanism by which the secure middleware layer can
protect the system from malicious or faulty applications.

Into the receiver code (for subscribers) we additionally generate a
receive buffer and receiver thread which pulls data from the buffer
according to the receiver profile.  In this scenario, the receiver
has a capacity with which it can handle incoming data, and it has a
finite buffer so it must use the OOB channel and measurements on the
incoming data stream to determine which senders to shut down to ensure
its buffer does not overflow.  When the buffer has had some time empty
(so that it's not in danger of running out of buffer space), the
receiver can use the OOB channel to inform the halted senders that it
is alright to send again.  Example traffic generation accuracy is
shown in Figure~\ref{fig:generation}.  The complete description of the
OOB channel, and the way the receiver limits the senders can be found
in Section~\ref{sec:ddos}.

\begin{figure}[ht!]
  %\centering
  \includegraphics[width=1.1\textwidth]{../doc/src/images/results/traffic_generation.png}
  \caption{Demonstration of the accuracy with which our traffic
    producers follow the specified profile.  The sloped regions
    (ca. 10, 20, 30 seconds) are a plotting artifact where the system
    has no data because the bandwidth is 0.}
  \label{fig:generation}
\end{figure}

\begin{definition}[Note:]
The measured bandwidth profile is calculated based on
recorded time series data of $[reception\_time,
  message\_size]$, so the bandwidth drops to nearly 0
periodically since the $\Delta t$ is so large between
the messages.
\end{definition}

\begin{definition}[Note:]
Our original implementation of traffic producers performed
	  better since they did not utilize a middleware layer and
	  relied instead on simple point to point ipv6 connections.
	  However, that code was less useful for system analysis
	  because it could do nothing aside from traffic production
	  and measurement; our current implementation which generates
	  traffic production code into component code is more
	  versatile for several reasons:

          \begin{itemize}
	  \item The component-based code integrates directly into our development
	    toolsuite and deployment framework so it can be easily deployed on
	    our cluster.
	  \item Configuring different system topologies or component to host
	    mappings (deployments) is simpler and more robust, allowing us to
	    perform more and more varied experiments.
	  \item The traffic production code can be removed (or the code can be
	    regenerated without the option selected) and the rest of the
	    component-based and middleware code is still useful as an actual
	    application.
          \end{itemize}
\end{definition}

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Distributed Denial of Service (DDoS) Detection}
\label{sec:ddos}

Denial-of-Service (DoS)\cite{rfc4732} and Distributed DoS (DDoS) attacks
can take many forms, but are generally classified as excessive traffic
from a large amount of (possibly heterogeneous) sources targeted
towards a single point or a single group.  Such attacks are common to
machines on the internet, but can also become a hazard for machines on
private networks which become infected or inadvertently expose an
input path for external malicious data.

These private or semi-private systems must have mechanisms for
detecting and mitigating such attacks, and the combination of our
design-time analysis and run-time measurement, detection, and
mitigation tools provides a form for such capability.  The goal of
this work is for a receiver, which is being targeted for attack by a
set of senders, to determine which of the senders are behaving
anomalously and prevent them from sending any more data.  In this way,
a group of senders performing a DDoS attack can be mitigated by the
targeted receiver.  Towards this goal we make the following changes
outlined below to our modeling/analysis framework and implementation.

If we relax the constraint from the design-time section that all
sender profiles are absolute and the system behavior is completely
known at design-time, then we not only expand the scope of
applications that can be supported but also enable meaningful anomaly
detection.

Whereas previously, profiles captured in their definition the
$data\ rate$ as a function of time that the application
produced, we now alter the definition to capture two parameters:
$mean\ data\ rate$ ($\mu$) and $max\ data\ rate$
($MDR$), which again are both functions of time.  Just as
before, these functions are constant-valued between successive values
of $t$ and are time-integrated to produce the $mean\ data$
and $max\ data$ cumulative profiles as functions of time.  With
this specification, we no longer know exactly how much data an
application will produce at a given point in time, but instead are
provided two values by the developer: the $mean$ and
$max$.

Now that we have these two profiles for the application, we could
simply analyze the $max$ data profile to determine buffer and latency
requirements, but this would end up wasting resources by allocating
memory and network resources of the system to the application even if
is not producing data at its \emph{max rate}.  Instead, we analyze the
system according to the $mean$ data profile to determine buffer
requirements and latency for the application in the system.  In doing
so, two buffer overflow risks are possible: 1) Sender-side buffer
overflow, and 2) Receiver-side buffer overflow.

We make the assumption that the application meters its sending to
prevent the first scenario, so that its data is not lost before making
it onto the network.  In this case, the sender can still send data at
a rate greater than the $mean$, but that rate is partially
governed by the capacity given to it by the node's network.

For the second case, we must ensure that there is no buffer overflow
on the receiver-side.  To enable this functionality, we must provide a
mechanism for the receiver to communicate with the sender.  This
push-back communication should travel through a channel outside the
communications channel that the application has access to, so that the
application, either maliciously or inadvertently, cannot disrupt this
push-back and in turn cause the receiver's buffer to overflow.  For
this reason, we add into the sender and receiver middleware an
out-of-band (OOB) channel that provides a communications layer between
all senders and receivers that is invisible to the application.  For
our component model and communications middleware, we have implemented
this OOB channel as a UDP multicast group.

Because the goal of this work is to only meter senders which are
producing \emph{too much} data, we must define what \emph{too much
  data} is.  Because we have developed these application profiles for
analysis, and these profiles describe the $\mu$ and $MDR$ of the
senders, they will be used to determine when a sender is sending too
much data.  In this paradigm, a sender is determined as behaving
anomalously (i.e. sending too much data) if the sender $S_i$ is
sending data at a rate $DR_i > \mu_i$.  The assumption implicit in
this comparison is that the receiver, to be able to make this
comparison, has full knowledge of $\mu_i$, since $DR_i$ is calculable
on the receiver side.  If the receiver's buffer is filling up, it
looks through the the measured $DR$ (within a certain window of time)
for each of the senders it has been receiving data from, and compares
it against the sender's $\mu$.  If the comparison is \emph{true}, it
uses the OOB channel to push back to that specific sender, informing
the sender-side middleware to stop transmitting data until the
receiver has re-enabled that sender's transmission.  When the receiver
has emptied it's buffer enough it can then use the OOB channel to
re-enable the disabled senders.  The algorithm used by the receiver to
determine which senders to limit is shown in Listing~\ref{lst:ddos_alg}.

\begin{listing}[ht!]
  \begin{minted}{python}
  reciever::limit_ddos( t_start, t_end )
  {
    for sender in senders
    {
      d_start = sender.received_data(t_start)
      d_end = sender.received_data(t_end)
      profile_d_start =
        sender.profile(t_start)
      profile_d_end =
        sender.profile(t_end)
      allowed_data = profile_d_end - profile_d_start
      actual_data = d_end - d_start
      if actual_data > allowed_data
      {
        sender.disable()
      }
    }
  }
  \end{minted}
  \caption{Algorithm used by receivers to determine which senders to
    limit.  The receiver only looks at the behavior of senders within
    the time window between $t_{start}$ and $t_{end}$, which is
    configurable.}
  \label{lst:ddos_alg}
\end{listing}


\begin{figure}[ht!]
  \centering
  \includegraphics[width=0.85\textwidth]{../doc/src/images/results/example_setup.png}
  \caption{Nodes in an example network and how they communicate (using
    pub/sub).}
  \label{fig:ddos}
\end{figure}

We have implemented the OOB channel communication into our sender and
receiver component code along with the profile measurement and
comparison.  Using these code generators, we are able to run
experiments validating that the receiver can properly manage its
buffer by throttling excessive senders during times of congestion. 

We have shown experimentally (for the system in Figure~\ref{fig:ddos})
that, for example, a receiver side buffer size of 400000 bits, which
would normally grow to 459424 bits because of excessive data pumps on
the sender sides, is kept to 393792 by utilizing this out-of-band
channel and secure middleware.

\iffalse

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Network Resource Monitoring and Management Integrated into Component-Based Middleware}
\label{sec:drems}

\subsection{Problem}
Distributed, deployed CPS require design-time assurances of system
stability and security.  These assurances guarantee that resources and
communications must have some protection against propagating software
faults or malicious actors.  One such avenue for fault or attack
propagation is the system's communications network.  Systems provide
the computational resources, hardware access, and communications
required for their applications.  For example, the satellite cluster
provides (1) distributed processors which are shared by the
applications, (2) data from the on-board sensors provided by each
satellite, and (3) a wireless communications network.  During
deployment, the system enforces resource utilization limits on the
applications, e.g. memory or disk space limitations, which must be
broad to account for whatever the applications may need to do over
their lifetime.  However, application resource limits which do not
incorporate temporal behavior (i.e. static limits) are inefficient
since they waste resources allocated to applications not using them.
Furthermore, these static resource limits do not provide tight bounds
on application behavior and may create avenues for fault or attack
propagation.  An example of such resource reservation schemes
backfiring is a Distributed Denial of Service (DDoS) attack, in which
many compromised applications produce slightly more network traffic
than usual (but still within their limits) to produce a combined
network traffic profile that can effectively take their target off of
the network.

\subsection{Contributions}
\begin{itemize}
	\item We integrated our network resource modeling techniques
          into a system and application analysis and development
          tool-suite. The tool verified that the system could provide
          all the network resources (which varied as a function of
          time) required by the applications.  The accuracy of the
          predictions was described in
          Section~\ref{sec:experimentalVerification}.
	\item Into the application's generated middleware interface
          code we integrated measurement, detection, and mitigation
          code which (1) measured the characteristics of the
          application's network traffic, (2) detected if the
          application's network traffic exceeded its profile that was
          provided during system analysis, and (3) blocked all traffic
          from leaving application-space (i.e. it did not get into
          kernel-space) which was detected as having exceeded the
          profile.  We showed that this management code allowed
          properly shaped traffic onto the network and blocked
          improperly shaped traffic.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Network Application Fault/Anomaly Classification}
\label{sec:classification}

\subsection{Problem}
For distributed systems which must ensure resource availability and
system stability, a key aspect of the infrastructure is detection and
mitigation of faults or anomalies.  With respect to network resources,
an example is checking source and destination for communications to
enforce only authorized communication flows are present in the system.
However, software glitches or compromised applications can exceed
system resources that they have been allocated.  As described in the
previous section, higher-fidelity resource modeling and monitoring is
required to prevent such faults or compromises from propagating
throughout the system.  However, mitigating the propagation only
solves part of the problem; ideally the system should classify the
type of fault or anomaly and begin diagnostics to trace the
fault/anomaly back to its origin.

\subsection{Proposed Contributions}
\begin{itemize}
	\item We will use our testbed to run distributed network tests
          to classify certain types of anomalies, e.g. DDoS attacks
          from compromised applications within the cluster.
	\item We will use the network resource utilization
          measurements gained from the tests to derive metrics which
          allow us to differentiate between classes of behavior,
          e.g. standard/stable application behavior vs. DDoS behavior.
	\item We will then use the classifications to show that the
          system can detect these types of attacks, mitigate their
          propagation, and report the attack to the system's manager.
\end{itemize}

\fi
